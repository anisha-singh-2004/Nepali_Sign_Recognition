{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d17f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image files in folder: ['frame_0000.jpg', 'frame_0001.jpg', 'frame_0002.jpg', 'frame_0003.jpg', 'frame_0004.jpg', 'frame_0005.jpg', 'frame_0006.jpg', 'frame_0007.jpg', 'frame_0008.jpg', 'frame_0009.jpg', 'frame_0010.jpg', 'frame_0011.jpg', 'frame_0012.jpg', 'frame_0013.jpg', 'frame_0014.jpg', 'frame_0015.jpg', 'frame_0016.jpg', 'frame_0017.jpg', 'frame_0018.jpg', 'frame_0019.jpg', 'frame_0020.jpg', 'frame_0021.jpg', 'frame_0022.jpg', 'frame_0023.jpg', 'frame_0024.jpg', 'frame_0025.jpg', 'frame_0026.jpg', 'frame_0027.jpg', 'frame_0028.jpg', 'frame_0029.jpg', 'frame_0030.jpg', 'frame_0031.jpg', 'frame_0032.jpg', 'frame_0033.jpg', 'frame_0034.jpg', 'frame_0035.jpg', 'frame_0036.jpg', 'frame_0037.jpg', 'frame_0038.jpg', 'frame_0039.jpg', 'frame_0040.jpg', 'frame_0041.jpg', 'frame_0042.jpg', 'frame_0043.jpg', 'frame_0044.jpg', 'frame_0045.jpg', 'frame_0046.jpg', 'frame_0047.jpg', 'frame_0048.jpg', 'frame_0049.jpg', 'frame_0050.jpg', 'frame_0051.jpg', 'frame_0052.jpg', 'frame_0053.jpg', 'frame_0054.jpg', 'frame_0055.jpg', 'frame_0056.jpg', 'frame_0057.jpg', 'frame_0058.jpg', 'frame_0059.jpg', 'frame_0060.jpg', 'frame_0061.jpg', 'frame_0062.jpg', 'frame_0063.jpg', 'frame_0064.jpg', 'frame_0065.jpg', 'frame_0066.jpg', 'frame_0067.jpg', 'frame_0068.jpg', 'frame_0069.jpg', 'frame_0070.jpg', 'frame_0071.jpg', 'frame_0072.jpg', 'frame_0073.jpg', 'frame_0074.jpg', 'frame_0075.jpg', 'frame_0076.jpg', 'frame_0077.jpg', 'frame_0078.jpg', 'frame_0079.jpg', 'frame_0080.jpg', 'frame_0081.jpg', 'frame_0082.jpg']\n",
      "Output folder: C:\\Users\\anish\\Desktop\\GYA\n",
      "Processing image: frame_0000.jpg\n",
      "Processing image: frame_0001.jpg\n",
      "Processing image: frame_0002.jpg\n",
      "Processing image: frame_0003.jpg\n",
      "Processing image: frame_0004.jpg\n",
      "Processing image: frame_0005.jpg\n",
      "Processing image: frame_0006.jpg\n",
      "Processing image: frame_0007.jpg\n",
      "Processing image: frame_0008.jpg\n",
      "Processing image: frame_0009.jpg\n",
      "Processing image: frame_0010.jpg\n",
      "Processing image: frame_0011.jpg\n",
      "Processing image: frame_0012.jpg\n",
      "Processing image: frame_0013.jpg\n",
      "Processing image: frame_0014.jpg\n",
      "Processing image: frame_0015.jpg\n",
      "Processing image: frame_0016.jpg\n",
      "Processing image: frame_0017.jpg\n",
      "Processing image: frame_0018.jpg\n",
      "Processing image: frame_0019.jpg\n",
      "Processing image: frame_0020.jpg\n",
      "Processing image: frame_0021.jpg\n",
      "Processing image: frame_0022.jpg\n",
      "Processing image: frame_0023.jpg\n",
      "Processing image: frame_0024.jpg\n",
      "Processing image: frame_0025.jpg\n",
      "Processing image: frame_0026.jpg\n",
      "Processing image: frame_0027.jpg\n",
      "Processing image: frame_0028.jpg\n",
      "Processing image: frame_0029.jpg\n",
      "Processing image: frame_0030.jpg\n",
      "Processing image: frame_0031.jpg\n",
      "Processing image: frame_0032.jpg\n",
      "Processing image: frame_0033.jpg\n",
      "Processing image: frame_0034.jpg\n",
      "Processing image: frame_0035.jpg\n",
      "Processing image: frame_0036.jpg\n",
      "Processing image: frame_0037.jpg\n",
      "Processing image: frame_0038.jpg\n",
      "Processing image: frame_0039.jpg\n",
      "Processing image: frame_0040.jpg\n",
      "Processing image: frame_0041.jpg\n",
      "Processing image: frame_0042.jpg\n",
      "Processing image: frame_0043.jpg\n",
      "Processing image: frame_0044.jpg\n",
      "Processing image: frame_0045.jpg\n",
      "Processing image: frame_0046.jpg\n",
      "Processing image: frame_0047.jpg\n",
      "Processing image: frame_0048.jpg\n",
      "Processing image: frame_0049.jpg\n",
      "Processing image: frame_0050.jpg\n",
      "Processing image: frame_0051.jpg\n",
      "Processing image: frame_0052.jpg\n",
      "Processing image: frame_0053.jpg\n",
      "Processing image: frame_0054.jpg\n",
      "Processing image: frame_0055.jpg\n",
      "Processing image: frame_0056.jpg\n",
      "Processing image: frame_0057.jpg\n",
      "Processing image: frame_0058.jpg\n",
      "Processing image: frame_0059.jpg\n",
      "Processing image: frame_0060.jpg\n",
      "Processing image: frame_0061.jpg\n",
      "Processing image: frame_0062.jpg\n",
      "Processing image: frame_0063.jpg\n",
      "Processing image: frame_0064.jpg\n",
      "Processing image: frame_0065.jpg\n",
      "Processing image: frame_0066.jpg\n",
      "Processing image: frame_0067.jpg\n",
      "Processing image: frame_0068.jpg\n",
      "Processing image: frame_0069.jpg\n",
      "Processing image: frame_0070.jpg\n",
      "Processing image: frame_0071.jpg\n",
      "Processing image: frame_0072.jpg\n",
      "Processing image: frame_0073.jpg\n",
      "Processing image: frame_0074.jpg\n",
      "Processing image: frame_0075.jpg\n",
      "Processing image: frame_0076.jpg\n",
      "Processing image: frame_0077.jpg\n",
      "Processing image: frame_0078.jpg\n",
      "Processing image: frame_0079.jpg\n",
      "Processing image: frame_0080.jpg\n",
      "Processing image: frame_0081.jpg\n",
      "Processing image: frame_0082.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe hand detection\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)  # Set max_num_hands to 1\n",
    "\n",
    "# Load images from folder\n",
    "folder_path = r\"C:\\Users\\anish\\Desktop\\GYA_bright\"\n",
    "try:\n",
    "    image_files = os.listdir(folder_path)\n",
    "    print(\"Image files in folder:\", image_files)  # Debug statement\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder not found: {folder_path}\")\n",
    "    exit()\n",
    "\n",
    "# Output folder for cropped hand images\n",
    "output_folder = r'C:\\Users\\anish\\Desktop\\GYA'\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create output folder if it doesn't exist\n",
    "print(\"Output folder:\", output_folder)  # Debug statement\n",
    "\n",
    "# Define margin for expanding bounding box\n",
    "margin = 20  # Adjust this value according to your preference\n",
    "\n",
    "for image_file in image_files:\n",
    "    print(\"Processing image:\", image_file)  # Debug statement\n",
    "    # Read image\n",
    "    image = cv2.imread(os.path.join(folder_path, image_file))\n",
    "    if image is None:\n",
    "        print(f\"Error reading image: {image_file}\")  # Debug statement\n",
    "        continue  # Skip to the next image if the current one cannot be read\n",
    "    \n",
    "    # Detect hand in the image\n",
    "    results = hands.process(image)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            # Extract coordinates of hand landmarks\n",
    "            landmark_points = [(int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])) for landmark in hand_landmarks.landmark]\n",
    "            \n",
    "            # Convert landmarks to numpy array\n",
    "            landmark_points_np = np.array(landmark_points)\n",
    "            \n",
    "            # Compute bounding rectangle\n",
    "            bounding_box = cv2.boundingRect(landmark_points_np)\n",
    "            \n",
    "            # Expand bounding box\n",
    "            bounding_box_expanded = (\n",
    "                bounding_box[0] - margin,  # Left\n",
    "                bounding_box[1] - margin,  # Top\n",
    "                bounding_box[2] + 2 * margin,  # Width\n",
    "                bounding_box[3] + 2 * margin  # Height\n",
    "            )\n",
    "            \n",
    "            # Crop hand region from the image with the expanded bounding box\n",
    "            hand_cropped_expanded = image[\n",
    "                bounding_box_expanded[1]:bounding_box_expanded[1] + bounding_box_expanded[3],\n",
    "                bounding_box_expanded[0]:bounding_box_expanded[0] + bounding_box_expanded[2]\n",
    "            ]\n",
    "            \n",
    "            # Generate filename based on image name\n",
    "            output_filename = f\"{os.path.splitext(image_file)[0]}_hand_{i}_GYA.jpg\"  # Append '_hand_i_DHA' to the filename\n",
    "            \n",
    "            # Save cropped hand image to output folder\n",
    "            cv2.imwrite(os.path.join(output_folder, output_filename), hand_cropped_expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a25c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: frame_0000.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0001.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0002.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0003.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0004.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0005.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0006.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0007.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0008.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0009.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0010.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0011.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0012.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0013.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0014.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0015.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0016.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0017.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0018.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0019.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0020.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0021.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0022.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0023.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0024.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0025.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0026.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0027.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0028.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0029.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0030.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0031.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0032.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0033.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0034.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0035.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0036.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0037.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0038.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0039.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0040.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0041.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0042.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0043.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0044.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0045.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0046.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0047.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0048.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0049.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0050.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0051.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0052.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0053.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0054.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0055.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0056.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0057.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0058.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0059.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0060.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0061.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0062.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0063.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0064.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0065.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0066.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0067.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0068.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0069.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0070.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0071.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0072.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0073.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0074.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0075.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0076.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0077.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0078.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0079.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0080.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0081.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0082.jpg\n",
      "No hand detected in the image.\n"
     ]
    }
   ],
   "source": [
    "for image_file in image_files:\n",
    "    print(\"Processing image:\", image_file)  # Debug statement\n",
    "    # Read image\n",
    "    image = cv2.imread(os.path.join(folder_path, image_file))\n",
    "    if image is None:\n",
    "        print(f\"Error reading image: {image_file}\")  # Debug statement\n",
    "        continue  # Skip to the next image if the current one cannot be read\n",
    "    \n",
    "    # Detect hand in the image\n",
    "    results = hands.process(image)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        print(\"Detected hand in the image!\")  # Debug statement\n",
    "        for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            # Extract coordinates of hand landmarks\n",
    "            landmark_points = [(int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])) for landmark in hand_landmarks.landmark]\n",
    "            \n",
    "            # Convert landmarks to numpy array\n",
    "            landmark_points_np = np.array(landmark_points)\n",
    "            \n",
    "            # Compute bounding rectangle\n",
    "            bounding_box = cv2.boundingRect(landmark_points_np)\n",
    "            print(\"Bounding box:\", bounding_box)  # Debug statement\n",
    "            \n",
    "            # Expand bounding box\n",
    "            bounding_box_expanded = (\n",
    "                bounding_box[0] - margin,  # Left\n",
    "                bounding_box[1] - margin,  # Top\n",
    "                bounding_box[2] + 2 * margin,  # Width\n",
    "                bounding_box[3] + 2 * margin  # Height\n",
    "            )\n",
    "            \n",
    "            # Crop hand region from the image with the expanded bounding box\n",
    "            hand_cropped_expanded = image[\n",
    "                bounding_box_expanded[1]:bounding_box_expanded[1] + bounding_box_expanded[3],\n",
    "                bounding_box_expanded[0]:bounding_box_expanded[0] + bounding_box_expanded[2]\n",
    "            ]\n",
    "            \n",
    "            # Display cropped hand image\n",
    "            cv2.imshow(\"Cropped Hand\", hand_cropped_expanded)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            # Generate filename based on image name\n",
    "            output_filename = f\"{os.path.splitext(image_file)[0]}_hand_{i}_GYA.jpg\"  # Append '_hand_i_DHA' to the filename\n",
    "            \n",
    "            # Save cropped hand image to output folder\n",
    "            cv2.imwrite(os.path.join(output_folder, output_filename), hand_cropped_expanded)\n",
    "    else:\n",
    "        print(\"No hand detected in the image.\")  # Debug statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4629acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: frame_0000.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0001.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0002.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0003.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0004.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0005.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0006.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0007.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0008.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0009.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0010.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0011.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0012.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0013.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0014.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0015.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0016.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0017.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0018.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0019.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0020.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0021.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0022.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0023.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0024.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0025.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0026.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0027.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0028.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0029.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0030.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0031.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0032.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0033.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0034.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0035.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0036.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0037.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0038.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0039.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0040.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0041.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0042.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0043.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0044.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0045.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0046.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0047.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0048.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0049.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0050.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0051.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0052.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0053.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0054.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0055.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0056.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0057.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0058.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0059.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0060.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0061.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0062.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0063.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0064.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0065.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0066.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0067.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0068.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0069.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0070.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0071.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0072.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0073.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0074.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0075.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0076.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0077.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0078.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0079.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0080.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0081.jpg\n",
      "No hand detected in the image.\n",
      "Processing image: frame_0082.jpg\n",
      "No hand detected in the image.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the input folder path\n",
    "folder_path = r\"C:\\Users\\anish\\Desktop\\GYA_bright\"\n",
    "\n",
    "# Define other parameters\n",
    "margin = 30  # Margin to expand the bounding box\n",
    "\n",
    "# Process each image in the folder\n",
    "for image_file in os.listdir(folder_path):\n",
    "    if image_file.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Filter images by extension\n",
    "        print(\"Processing image:\", image_file)  # Debug statement\n",
    "        # Read image\n",
    "        image = cv2.imread(os.path.join(folder_path, image_file))\n",
    "        if image is None:\n",
    "            print(f\"Error reading image: {image_file}\")  # Debug statement\n",
    "            continue  # Skip to the next image if the current one cannot be read\n",
    "        \n",
    "        # Detect hand in the image\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            print(\"Detected hand in the image!\")  # Debug statement\n",
    "            for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                # Extract coordinates of hand landmarks\n",
    "                landmark_points = [(int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])) for landmark in hand_landmarks.landmark]\n",
    "                \n",
    "                # Convert landmarks to numpy array\n",
    "                landmark_points_np = np.array(landmark_points)\n",
    "                \n",
    "                # Compute bounding rectangle\n",
    "                bounding_box = cv2.boundingRect(landmark_points_np)\n",
    "                print(\"Bounding box:\", bounding_box)  # Debug statement\n",
    "                \n",
    "                # Expand bounding box\n",
    "                bounding_box_expanded = (\n",
    "                    bounding_box[0] - margin,  # Left\n",
    "                    bounding_box[1] - margin,  # Top\n",
    "                    bounding_box[2] + 2 * margin,  # Width\n",
    "                    bounding_box[3] + 2 * margin  # Height\n",
    "                )\n",
    "                \n",
    "                # Crop hand region from the image with the expanded bounding box\n",
    "                hand_cropped_expanded = image[\n",
    "                    bounding_box_expanded[1]:bounding_box_expanded[1] + bounding_box_expanded[3],\n",
    "                    bounding_box_expanded[0]:bounding_box_expanded[0] + bounding_box_expanded[2]\n",
    "                ]\n",
    "                \n",
    "                # Display cropped hand image\n",
    "                cv2.imshow(\"Cropped Hand\", hand_cropped_expanded)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                # Generate filename based on image name\n",
    "                output_filename = f\"{os.path.splitext(image_file)[0]}hand{i}_GYA.jpg\"  # Append '_hand_i_DHA' to the filename\n",
    "                \n",
    "                # Save cropped hand image to output folder\n",
    "                output_folder = r'C:\\Users\\anish\\Desktop\\hand'\n",
    "                cv2.imwrite(os.path.join(output_folder, output_filename), hand_cropped_expanded)\n",
    "        else:\n",
    "            print(\"No hand detected in the image.\")  # Debug statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ec70d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20231225::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load YOLO\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m net \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov3.weights\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov3.cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mgetLayerNames()\n\u001b[0;32m      7\u001b[0m output_layers \u001b[38;5;241m=\u001b[39m [layer_names[i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m net\u001b[38;5;241m.\u001b[39mgetUnconnectedOutLayers()]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20231225::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Define the input folder path\n",
    "folder_path = r\"C:\\Users\\anish\\Desktop\\GYA_bright\"\n",
    "\n",
    "# Define other parameters\n",
    "margin = 30  # Margin to expand the bounding box\n",
    "\n",
    "# Process each image in the folder\n",
    "for image_file in os.listdir(folder_path):\n",
    "    if image_file.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Filter images by extension\n",
    "        print(\"Processing image:\", image_file)  # Debug statement\n",
    "        # Read image\n",
    "        image = cv2.imread(os.path.join(folder_path, image_file))\n",
    "        if image is None:\n",
    "            print(f\"Error reading image: {image_file}\")  # Debug statement\n",
    "            continue  # Skip to the next image if the current one cannot be read\n",
    "\n",
    "        # Get image dimensions\n",
    "        height, width, channels = image.shape\n",
    "\n",
    "        # Detect objects using YOLO\n",
    "        blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "\n",
    "        # Process detection results\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5 and class_id == 0:  # Assuming class_id 0 corresponds to hands\n",
    "                    # Get bounding box coordinates\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # Compute bounding box coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    # Expand bounding box\n",
    "                    x = max(0, x - margin)\n",
    "                    y = max(0, y - margin)\n",
    "                    w = min(width - 1, w + 2 * margin)\n",
    "                    h = min(height - 1, h + 2 * margin)\n",
    "\n",
    "                    # Crop hand region from the image\n",
    "                    hand_cropped_expanded = image[y:y+h, x:x+w]\n",
    "\n",
    "                    # Display the cropped hand image\n",
    "                    cv2.imshow(\"Cropped Hand\", hand_cropped_expanded)\n",
    "                    cv2.waitKey(0)\n",
    "                    cv2.destroyAllWindows()\n",
    "\n",
    "                    # Generate filename based on image name\n",
    "                    output_filename = f\"{os.path.splitext(image_file)[0]}hand{i}_GYA.jpg\"  # Append '_hand_i_DHA' to the filename\n",
    "\n",
    "                    # Save cropped hand image to output folder\n",
    "                    output_folder = r'C:\\Users\\anish\\Desktop\\hand'\n",
    "                    cv2.imwrite(os.path.join(output_folder, output_filename), hand_cropped_expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c16aa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: frame_0000.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (381, 454, 217, 250)\n",
      "Processing image: frame_0001.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (387, 447, 217, 247)\n",
      "Processing image: frame_0002.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (394, 443, 214, 248)\n",
      "Processing image: frame_0003.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (396, 438, 216, 248)\n",
      "Processing image: frame_0004.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (402, 436, 213, 243)\n",
      "Processing image: frame_0005.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (406, 433, 211, 242)\n",
      "Processing image: frame_0006.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (409, 432, 211, 242)\n",
      "Processing image: frame_0007.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (412, 431, 215, 240)\n",
      "Processing image: frame_0008.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (417, 431, 212, 239)\n",
      "Processing image: frame_0009.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (419, 430, 212, 238)\n",
      "Processing image: frame_0010.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (423, 429, 212, 241)\n",
      "Processing image: frame_0011.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (427, 430, 210, 242)\n",
      "Processing image: frame_0012.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (427, 431, 213, 245)\n",
      "Processing image: frame_0013.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (431, 433, 209, 246)\n",
      "Processing image: frame_0014.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (431, 438, 210, 240)\n",
      "Processing image: frame_0015.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (432, 441, 209, 242)\n",
      "Processing image: frame_0016.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (434, 443, 212, 242)\n",
      "Processing image: frame_0017.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (432, 450, 211, 238)\n",
      "Processing image: frame_0018.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (432, 453, 211, 234)\n",
      "Processing image: frame_0019.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (433, 455, 212, 237)\n",
      "Processing image: frame_0020.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (433, 461, 212, 231)\n",
      "Processing image: frame_0021.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (433, 464, 212, 231)\n",
      "Processing image: frame_0022.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (435, 469, 209, 221)\n",
      "Processing image: frame_0023.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (434, 470, 212, 223)\n",
      "Processing image: frame_0024.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (435, 473, 209, 220)\n",
      "Processing image: frame_0025.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (435, 475, 211, 217)\n",
      "Processing image: frame_0026.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (435, 476, 211, 222)\n",
      "Processing image: frame_0027.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (435, 477, 210, 220)\n",
      "Processing image: frame_0028.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (437, 477, 211, 223)\n",
      "Processing image: frame_0029.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 478, 208, 220)\n",
      "Processing image: frame_0030.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (436, 478, 211, 220)\n",
      "Processing image: frame_0031.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (436, 479, 210, 219)\n",
      "Processing image: frame_0032.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (436, 479, 211, 216)\n",
      "Processing image: frame_0033.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (436, 479, 210, 213)\n",
      "Processing image: frame_0034.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 479, 207, 216)\n",
      "Processing image: frame_0035.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (437, 478, 210, 217)\n",
      "Processing image: frame_0036.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 478, 209, 216)\n",
      "Processing image: frame_0037.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 479, 208, 215)\n",
      "Processing image: frame_0038.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (437, 478, 210, 216)\n",
      "Processing image: frame_0039.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (437, 479, 210, 216)\n",
      "Processing image: frame_0040.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 479, 209, 216)\n",
      "Processing image: frame_0041.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (437, 482, 210, 214)\n",
      "Processing image: frame_0042.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 481, 209, 216)\n",
      "Processing image: frame_0043.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (437, 482, 210, 215)\n",
      "Processing image: frame_0044.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (439, 483, 210, 214)\n",
      "Processing image: frame_0045.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (439, 483, 209, 214)\n",
      "Processing image: frame_0046.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 485, 211, 214)\n",
      "Processing image: frame_0047.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 486, 214, 216)\n",
      "Processing image: frame_0048.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (439, 487, 212, 215)\n",
      "Processing image: frame_0049.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 488, 214, 215)\n",
      "Processing image: frame_0050.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (439, 491, 212, 214)\n",
      "Processing image: frame_0051.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (438, 491, 211, 212)\n",
      "Processing image: frame_0052.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 495, 211, 211)\n",
      "Processing image: frame_0053.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (439, 496, 211, 210)\n",
      "Processing image: frame_0054.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 496, 211, 211)\n",
      "Processing image: frame_0055.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (439, 497, 212, 212)\n",
      "Processing image: frame_0056.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 499, 212, 209)\n",
      "Processing image: frame_0057.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (439, 499, 213, 209)\n",
      "Processing image: frame_0058.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 499, 212, 209)\n",
      "Processing image: frame_0059.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 500, 211, 208)\n",
      "Processing image: frame_0060.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (441, 500, 210, 207)\n",
      "Processing image: frame_0061.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 499, 211, 209)\n",
      "Processing image: frame_0062.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 500, 211, 210)\n",
      "Processing image: frame_0063.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 503, 210, 207)\n",
      "Processing image: frame_0064.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 502, 212, 210)\n",
      "Processing image: frame_0065.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (441, 502, 209, 208)\n",
      "Processing image: frame_0066.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (442, 501, 212, 208)\n",
      "Processing image: frame_0067.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (442, 500, 212, 209)\n",
      "Processing image: frame_0068.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (441, 502, 212, 208)\n",
      "Processing image: frame_0069.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (441, 502, 213, 209)\n",
      "Processing image: frame_0070.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 501, 213, 210)\n",
      "Processing image: frame_0071.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 502, 212, 207)\n",
      "Processing image: frame_0072.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (440, 502, 212, 208)\n",
      "Processing image: frame_0073.jpg\n",
      "Detected hand in the image!\n",
      "Bounding box: (442, 502, 212, 209)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe hand detection\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)  # Set max_num_hands to 1\n",
    "\n",
    "# Define the input folder path\n",
    "folder_path = r\"C:\\Users\\anish\\Desktop\\bright\\YAN bright\"\n",
    "\n",
    "# Define the output folder path\n",
    "output_folder = r'C:\\Users\\anish\\Desktop\\hand'\n",
    "\n",
    "# Define other parameters\n",
    "margin = 30  # Margin to expand the bounding box\n",
    "\n",
    "# Process each image in the folder\n",
    "for image_file in os.listdir(folder_path):\n",
    "    if image_file.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Filter images by extension\n",
    "        print(\"Processing image:\", image_file)  # Debug statement\n",
    "        # Read image\n",
    "        image = cv2.imread(os.path.join(folder_path, image_file))\n",
    "        if image is None:\n",
    "            print(f\"Error reading image: {image_file}\")  # Debug statement\n",
    "            continue  # Skip to the next image if the current one cannot be read\n",
    "        \n",
    "        # Detect hand in the image\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            print(\"Detected hand in the image!\")  # Debug statement\n",
    "            for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                # Extract coordinates of hand landmarks\n",
    "                landmark_points = [(int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])) for landmark in hand_landmarks.landmark]\n",
    "                \n",
    "                # Convert landmarks to numpy array\n",
    "                landmark_points_np = np.array(landmark_points)\n",
    "                \n",
    "                # Compute bounding rectangle\n",
    "                bounding_box = cv2.boundingRect(landmark_points_np)\n",
    "                print(\"Bounding box:\", bounding_box)  # Debug statement\n",
    "                \n",
    "                # Expand bounding box\n",
    "                bounding_box_expanded = (\n",
    "                    max(0, bounding_box[0] - margin),  # Left\n",
    "                    max(0, bounding_box[1] - margin),  # Top\n",
    "                    bounding_box[2] + 2 * margin,  # Width\n",
    "                    bounding_box[3] + 2 * margin  # Height\n",
    "                )\n",
    "                \n",
    "                # Crop hand region from the image with the expanded bounding box\n",
    "                hand_cropped_expanded = image[\n",
    "                    bounding_box_expanded[1]:bounding_box_expanded[1] + bounding_box_expanded[3],\n",
    "                    bounding_box_expanded[0]:bounding_box_expanded[0] + bounding_box_expanded[2]\n",
    "                ]\n",
    "                \n",
    "                # Generate filename based on image name\n",
    "                output_filename = f\"{os.path.splitext(image_file)[0]}_hand_{i}YAN.jpg\"  # Append '_hand_i_DHA' to the filename\n",
    "                \n",
    "                # Save cropped hand image to output folder\n",
    "                cv2.imwrite(os.path.join(output_folder, output_filename), hand_cropped_expanded)\n",
    "        else:\n",
    "            print(\"No hand detected in the image.\")  # Debug statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881e1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46096517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
